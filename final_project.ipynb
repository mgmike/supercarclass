{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sufficient-sodium",
   "metadata": {},
   "source": [
    "# Michael Eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-pursuit",
   "metadata": {},
   "source": [
    "# Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "skilled-superior",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "classes = ['dog', 'cat']\n",
    "num_classes = len(classes)\n",
    "learning_rate = 1E-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-hardwood",
   "metadata": {},
   "source": [
    "# Re orginaize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# sorts images into two new folders, dog and cat, in the train directory \n",
    "def split_images_by_class(directory, classes):\n",
    "    file_list = os.listdir(directory)\n",
    "\n",
    "    for c in classes:\n",
    "        os.mkdir('%s/%s' %(directory, c))\n",
    "    \n",
    "    for filename in file_list:\n",
    "        for c in classes:\n",
    "            if c in filename:\n",
    "                shutil.move('%s/%s' %(directory, filename), '%s/%s/%s' %(directory, c, filename))\n",
    "                \n",
    "# splits data from train into a new directory, test or val by a ratio\n",
    "def redistribute_images(directory, classes, dir1='/train/', dir2='/test/', train_test_ratio=0.9):\n",
    "    if not os.path.exists(directory + dir1[:len(dir1) - 1]):\n",
    "        os.mkdir(directory + dir1[:len(dir1) - 1])        \n",
    "    if not os.path.exists(directory + dir2[:len(dir1) - 1]):\n",
    "        os.mkdir(directory + dir2[:len(dir1) - 1])\n",
    "            \n",
    "    for c in classes:\n",
    "        if not os.path.exists(directory + dir1 + c):\n",
    "            os.mkdir(directory + dir1 + c)\n",
    "        if not os.path.exists(directory + dir2 + c):\n",
    "            os.mkdir(directory + dir2 + c)\n",
    "        train_list = os.listdir(directory + dir1 + c)\n",
    "        test_list = os.listdir(directory + dir2 + c)\n",
    "\n",
    "        for element in test_list:\n",
    "            train_list.append(test_list.pop(0))\n",
    "        \n",
    "        total = len(train_list)\n",
    "        while len(test_list) < (total * (1 - train_test_ratio)):\n",
    "            test_list.append(train_list.pop(0))\n",
    "        for filename in train_list:\n",
    "            if os.path.exists(directory + dir2 + c + '/' + filename):\n",
    "                shutil.move(directory + dir2 + c + '/'  + filename, directory + dir1 + c + '/'  + filename)\n",
    "        for filename in test_list:\n",
    "            if os.path.exists(directory + dir1 + c + '/' + filename):\n",
    "                shutil.move(directory + dir1 + c + '/'  + filename, directory + dir2 + c + '/'  + filename)\n",
    "\n",
    "split_images_by_class(cwd + '/train', classes)\n",
    "redistribute_images(cwd, classes)\n",
    "redistribute_images(cwd, classes, dir2='/val/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-clothing",
   "metadata": {},
   "source": [
    "# Create Image Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-wrapping",
   "metadata": {},
   "source": [
    "Now that the data is organized in a scheme that ImageDataGenerator can read, ImageDataGenerators are made for train, validation, test and the actual submission data. The training data gen includes data augmentation features such as rotation, zoom, horizontal flip and more. This gives the network more training samples for free during each epoch. Shuffle is set to false on the submission generator so that the image number and the prediction can be matched. It is true by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "assumed-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20250 images belonging to 2 classes.\n",
      "Found 2250 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #featurewise_std_normalization=True, \n",
    "    #featurewise_center=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    cwd + '/train',\n",
    "    target_size=(224,224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    cwd + '/val',\n",
    "    target_size=(224,224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    cwd + '/test',\n",
    "    target_size=(224,224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical')\n",
    "\n",
    "submission_generator = test_datagen.flow_from_directory(\n",
    "    cwd + '/submission',\n",
    "    shuffle=False,\n",
    "    target_size=(224,224),\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-sellers",
   "metadata": {},
   "source": [
    "# Build pretrained vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-leave",
   "metadata": {},
   "source": [
    "The pretrained convolution layers are used from vgg16, followed by two Dense layers. The first dense layer has 50% dropout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quick-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import AveragePooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "def build_vgg_pretrained(freeze_layers=0):\n",
    "    model = Sequential()\n",
    "    vgg16 = VGG16(input_shape=(224,224,3), classes=num_classes, include_top=False)\n",
    "    for layer in vgg16.layers[:freeze_layers]:\n",
    "        layer.tranable = False\n",
    "    model.add(vgg16)\n",
    "    model.add(AveragePooling2D((3,3), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer=glorot_uniform(seed=0)))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_initializer=glorot_uniform(seed=0)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "different-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 17,075,522\n",
      "Trainable params: 17,075,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = build_vgg_pretrained(freeze_layers=10)\n",
    "vgg.compile(loss='categorical_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=learning_rate * 5),\n",
    "             metrics=['acc'])\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-dallas",
   "metadata": {},
   "source": [
    "# Train and evaluate network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-access",
   "metadata": {},
   "source": [
    "Train the network on the train generator and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "polish-islam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "316/316 [==============================] - 174s 525ms/step - loss: 0.6309 - acc: 0.6239 - val_loss: 0.1586 - val_acc: 0.9344\n",
      "Epoch 2/3\n",
      "316/316 [==============================] - 161s 509ms/step - loss: 0.1711 - acc: 0.9319 - val_loss: 0.0939 - val_acc: 0.9647\n",
      "Epoch 3/3\n",
      "316/316 [==============================] - 159s 502ms/step - loss: 0.1079 - acc: 0.9582 - val_loss: 0.0526 - val_acc: 0.9799\n"
     ]
    }
   ],
   "source": [
    "history = vgg.fit(train_generator,\n",
    "                steps_per_epoch=316,\n",
    "                epochs=3,\n",
    "                validation_data=val_generator,\n",
    "                validation_steps=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-affair",
   "metadata": {},
   "source": [
    "Evaluate the network on new test data it has never seen. This test data is just a subset of the original data in the train folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stuffed-taiwan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 6s 148ms/step - loss: 0.0578 - acc: 0.9816\n"
     ]
    }
   ],
   "source": [
    "test_loss = vgg.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-prospect",
   "metadata": {},
   "source": [
    "Predict the class of the unlabeled data in the given 'test1' and group the file number with its prediction in a list then sort the list. The generator sorts the files by amount of zeros instead of the actual number. For instance, the output was 1, 10, 100, 1000, 10000, 100000, 100001, 100002, ... This was sorted correctly in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "precious-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_predictions(generator):\n",
    "    predictions = vgg.predict(generator)\n",
    "    names = generator.filenames\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        index = int(re.findall(r\"[\\d]+\", names[i])[0])\n",
    "        if prediction[0] > prediction[1]:\n",
    "            output.append([index, 0])\n",
    "        else:\n",
    "            output.append([index, 1])\n",
    "\n",
    "    output.sort(key = lambda a: a[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "supposed-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_predictions(submission_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "optical-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as submission_file:\n",
    "    submission_file.write('id, label\\n')\n",
    "    submission_file.writelines(\"%s,%s\\n\" %(str(element[0]), str(element[1])) for element in output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs583",
   "language": "python",
   "name": "cs583"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
